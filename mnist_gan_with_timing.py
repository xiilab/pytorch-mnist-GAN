#!/usr/bin/env python3
"""
PyTorch MNIST GAN with Timing Measurements
ì£¼ì¸ë‹˜ì„ ìœ„í•œ ì‹œê°„ ì¸¡ì • ê¸°ëŠ¥ì´ í¬í•¨ëœ MNIST GAN êµ¬í˜„
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.autograd import Variable
from torchvision.utils import save_image
import time
import os
from datetime import datetime
import tempfile


class Generator(nn.Module):
    """ìƒì„±ì ë„¤íŠ¸ì›Œí¬"""
    def __init__(self, g_input_dim, g_output_dim):
        super(Generator, self).__init__()       
        self.fc1 = nn.Linear(g_input_dim, 256)
        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)
        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)
        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)
    
    def forward(self, x): 
        x = F.leaky_relu(self.fc1(x), 0.2)
        x = F.leaky_relu(self.fc2(x), 0.2)
        x = F.leaky_relu(self.fc3(x), 0.2)
        return torch.tanh(self.fc4(x))


class Discriminator(nn.Module):
    """íŒë³„ì ë„¤íŠ¸ì›Œí¬"""
    def __init__(self, d_input_dim):
        super(Discriminator, self).__init__()
        self.fc1 = nn.Linear(d_input_dim, 1024)
        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)
        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)
        self.fc4 = nn.Linear(self.fc3.out_features, 1)
    
    def forward(self, x):
        x = F.leaky_relu(self.fc1(x), 0.2)
        x = F.dropout(x, 0.3)
        x = F.leaky_relu(self.fc2(x), 0.2)
        x = F.dropout(x, 0.3)
        x = F.leaky_relu(self.fc3(x), 0.2)
        x = F.dropout(x, 0.3)
        return torch.sigmoid(self.fc4(x))


class MNISTGANTrainer:
    """MNIST GAN í›ˆë ¨ í´ë˜ìŠ¤"""
    
    def __init__(self, batch_size=100, z_dim=100, lr=0.0002, device=None):
        self.batch_size = batch_size
        self.z_dim = z_dim
        self.lr = lr
        # ë””ë°”ì´ìŠ¤ ìš°ì„ ìˆœìœ„: CUDA > MPS > CPU (ì•ˆì „í•œ CUDA ê°ì§€ í¬í•¨)
        if device:
            self.device = device
        else:
            self.device = self._get_safe_device()
        
        # ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ë³€ìˆ˜ë“¤
        self.training_times = []
        self.epoch_times = []
        self.total_start_time = None
        
        print(f"ì£¼ì¸ë‹˜, ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ë°ì´í„° ë¡œë” ì„¤ì •
        self._setup_data_loaders()
        
        # ë„¤íŠ¸ì›Œí¬ ì´ˆê¸°í™”
        self._setup_networks()
        
        # ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
        self._setup_training_components()
        
        # ìƒ˜í”Œ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('./samples', exist_ok=True)
        
        # ë””ìŠ¤í¬ ì„±ëŠ¥ ì¸¡ì • (í•œ ë²ˆë§Œ ì‹¤í–‰)
        self.disk_performance = self.measure_disk_performance()
    
    def _get_safe_device(self):
        """ì•ˆì „í•œ ë””ë°”ì´ìŠ¤ ê°ì§€ ë° ì„¤ì •"""
        try:
            # CUDA ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸ ë° ì‹¤ì œ í…ŒìŠ¤íŠ¸
            if torch.cuda.is_available():
                # ê°„ë‹¨í•œ í…ì„œ ì—°ì‚°ìœ¼ë¡œ CUDA ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥ì„± í…ŒìŠ¤íŠ¸
                test_tensor = torch.tensor([1.0]).cuda()
                _ = test_tensor + 1
                print(f"ì£¼ì¸ë‹˜, CUDA ë””ë°”ì´ìŠ¤ ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name()}")
                return torch.device('cuda')
        except Exception as e:
            print(f"CUDA ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ, CPUë¡œ ì „í™˜: {e}")
        
        try:
            # MPS (Apple Silicon) í™•ì¸
            if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                test_tensor = torch.tensor([1.0]).to('mps')
                _ = test_tensor + 1
                print("ì£¼ì¸ë‹˜, MPS ë””ë°”ì´ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ (Apple Silicon)")
                return torch.device('mps')
        except Exception as e:
            print(f"MPS ì‚¬ìš© ì¤‘ ì˜¤ë¥˜ ë°œìƒ, CPUë¡œ ì „í™˜: {e}")
        
        # ê¸°ë³¸ê°’: CPU
        print("ì£¼ì¸ë‹˜, CPU ë””ë°”ì´ìŠ¤ ì‚¬ìš©")
        return torch.device('cpu')
    
    def measure_disk_performance(self):
        """ë””ìŠ¤í¬ I/O ì„±ëŠ¥ ì¸¡ì •"""
        print(f"\nğŸ’¿ ë””ìŠ¤í¬ I/O ì„±ëŠ¥ ì¸¡ì •:")
        
        # ê°„ë‹¨í•œ ë””ìŠ¤í¬ ì†ë„ í…ŒìŠ¤íŠ¸
        test_file_size = 100 * 1024 * 1024  # 100MB
        test_data = b'0' * (1024 * 1024)  # 1MB ì²­í¬
        
        try:
            with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                tmp_path = tmp_file.name
                
                # ì“°ê¸° ì†ë„ ì¸¡ì •
                start_time = time.time()
                for _ in range(100):  # 100MB ì“°ê¸°
                    tmp_file.write(test_data)
                tmp_file.flush()
                os.fsync(tmp_file.fileno())  # ê°•ì œë¡œ ë””ìŠ¤í¬ì— ì“°ê¸°
                write_time = time.time() - start_time
                write_speed = test_file_size / write_time / (1024**2)  # MB/s
                
            # ì½ê¸° ì†ë„ ì¸¡ì •
            start_time = time.time()
            with open(tmp_path, 'rb') as f:
                while f.read(1024 * 1024):  # 1MBì”© ì½ê¸°
                    pass
            read_time = time.time() - start_time
            read_speed = test_file_size / read_time / (1024**2)  # MB/s
            
            print(f"   - ìˆœì°¨ ì“°ê¸° ì†ë„: {write_speed:.1f} MB/s")
            print(f"   - ìˆœì°¨ ì½ê¸° ì†ë„: {read_speed:.1f} MB/s")
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(tmp_path)
            
            return {'write_speed': write_speed, 'read_speed': read_speed}
            
        except Exception as e:
            print(f"   - ë””ìŠ¤í¬ ì†ë„ ì¸¡ì • ì‹¤íŒ¨: {e}")
            return {'write_speed': 0, 'read_speed': 0}
    
    def _setup_data_loaders(self):
        """ë°ì´í„° ë¡œë” ì„¤ì •"""
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=(0.5,), std=(0.5,))
        ])
        
        train_dataset = datasets.MNIST(root='./mnist_data/', train=True, 
                                     transform=transform, download=True)
        test_dataset = datasets.MNIST(root='./mnist_data/', train=False, 
                                    transform=transform, download=False)
        
        self.train_loader = torch.utils.data.DataLoader(
            dataset=train_dataset, batch_size=self.batch_size, shuffle=True)
        self.test_loader = torch.utils.data.DataLoader(
            dataset=test_dataset, batch_size=self.batch_size, shuffle=False)
        
        # MNIST ì´ë¯¸ì§€ ì°¨ì› (PyTorch ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•´ ìˆ˜ì •)
        if hasattr(train_dataset, 'data'):
            self.mnist_dim = train_dataset.data.size(1) * train_dataset.data.size(2)
        else:
            self.mnist_dim = train_dataset.train_data.size(1) * train_dataset.train_data.size(2)
        print(f"MNIST ì´ë¯¸ì§€ ì°¨ì›: {self.mnist_dim}")
    
    def _setup_networks(self):
        """ë„¤íŠ¸ì›Œí¬ ì´ˆê¸°í™”"""
        self.G = Generator(g_input_dim=self.z_dim, g_output_dim=self.mnist_dim).to(self.device)
        self.D = Discriminator(self.mnist_dim).to(self.device)
        
        print("ìƒì„±ì ë„¤íŠ¸ì›Œí¬:")
        print(self.G)
        print("\níŒë³„ì ë„¤íŠ¸ì›Œí¬:")
        print(self.D)
    
    def _setup_training_components(self):
        """í›ˆë ¨ êµ¬ì„± ìš”ì†Œ ì„¤ì •"""
        self.criterion = nn.BCELoss()
        self.G_optimizer = optim.Adam(self.G.parameters(), lr=self.lr)
        self.D_optimizer = optim.Adam(self.D.parameters(), lr=self.lr)
    
    def train_discriminator(self, x):
        """íŒë³„ì í›ˆë ¨"""
        self.D.zero_grad()
        
        # í˜„ì¬ ë°°ì¹˜ í¬ê¸° (ë§ˆì§€ë§‰ ë°°ì¹˜ëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
        current_batch_size = x.size(0)
        
        # ì‹¤ì œ ë°ì´í„°ë¡œ í›ˆë ¨
        x_real = x.view(-1, self.mnist_dim)
        y_real = torch.ones(current_batch_size, 1)
        x_real, y_real = Variable(x_real.to(self.device)), Variable(y_real.to(self.device))
        
        D_output = self.D(x_real)
        D_real_loss = self.criterion(D_output, y_real)
        
        # ê°€ì§œ ë°ì´í„°ë¡œ í›ˆë ¨
        z = Variable(torch.randn(current_batch_size, self.z_dim).to(self.device))
        x_fake = self.G(z)
        y_fake = Variable(torch.zeros(current_batch_size, 1).to(self.device))
        
        D_output = self.D(x_fake)
        D_fake_loss = self.criterion(D_output, y_fake)
        
        # ì—­ì „íŒŒ ë° ìµœì í™”
        D_loss = D_real_loss + D_fake_loss
        D_loss.backward()
        self.D_optimizer.step()
        
        return D_loss.data.item()
    
    def train_generator(self, batch_size):
        """ìƒì„±ì í›ˆë ¨"""
        self.G.zero_grad()
        
        z = Variable(torch.randn(batch_size, self.z_dim).to(self.device))
        y = Variable(torch.ones(batch_size, 1).to(self.device))
        
        G_output = self.G(z)
        D_output = self.D(G_output)
        G_loss = self.criterion(D_output, y)
        
        # ì—­ì „íŒŒ ë° ìµœì í™”
        G_loss.backward()
        self.G_optimizer.step()
        
        return G_loss.data.item()
    
    def train(self, n_epochs=200, save_interval=50):
        """GAN í›ˆë ¨"""
        print(f"\nì£¼ì¸ë‹˜, {n_epochs} ì—í¬í¬ ë™ì•ˆ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        self.total_start_time = time.time()
        
        for epoch in range(1, n_epochs + 1):
            epoch_start_time = time.time()
            
            D_losses, G_losses = [], []
            
            for batch_idx, (x, _) in enumerate(self.train_loader):
                # íŒë³„ì í›ˆë ¨
                d_loss = self.train_discriminator(x)
                D_losses.append(d_loss)
                
                # ìƒì„±ì í›ˆë ¨
                g_loss = self.train_generator(x.size(0))
                G_losses.append(g_loss)
            
            epoch_time = time.time() - epoch_start_time
            self.epoch_times.append(epoch_time)
            
            # ì—í¬í¬ ê²°ê³¼ ì¶œë ¥
            avg_d_loss = torch.mean(torch.FloatTensor(D_losses))
            avg_g_loss = torch.mean(torch.FloatTensor(G_losses))
            
            print(f'[{epoch}/{n_epochs}]: loss_d: {avg_d_loss:.3f}, loss_g: {avg_g_loss:.3f}, '
                  f'ì‹œê°„: {epoch_time:.2f}ì´ˆ')
            
            # ì£¼ê¸°ì ìœ¼ë¡œ ìƒ˜í”Œ ì´ë¯¸ì§€ ì €ì¥
            if epoch % save_interval == 0:
                self.generate_samples(epoch)
        
        total_time = time.time() - self.total_start_time
        self.print_timing_summary(total_time, n_epochs)
        
        # ìµœì¢… ìƒ˜í”Œ ìƒì„±
        self.generate_samples('final')
    
    def generate_samples(self, epoch):
        """ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥"""
        with torch.no_grad():
            test_z = Variable(torch.randn(self.batch_size, self.z_dim).to(self.device))
            generated = self.G(test_z)
            
            filename = f'./samples/sample_epoch_{epoch}.png'
            save_image(generated.view(generated.size(0), 1, 28, 28), filename)
            print(f"ìƒ˜í”Œ ì´ë¯¸ì§€ ì €ì¥: {filename}")
    
    def print_timing_summary(self, total_time, n_epochs):
        """ì‹œê°„ ì¸¡ì • ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ì£¼ì¸ë‹˜ì„ ìœ„í•œ í›ˆë ¨ ì‹œê°„ ìš”ì•½")
        print("="*60)
        print(f"ì´ í›ˆë ¨ ì‹œê°„: {total_time:.2f}ì´ˆ ({total_time/60:.2f}ë¶„)")
        print(f"í‰ê·  ì—í¬í¬ ì‹œê°„: {sum(self.epoch_times)/len(self.epoch_times):.2f}ì´ˆ")
        print(f"ìµœë¹ ë¥¸ ì—í¬í¬: {min(self.epoch_times):.2f}ì´ˆ")
        print(f"ìµœëŠë¦° ì—í¬í¬: {max(self.epoch_times):.2f}ì´ˆ")
        print(f"ì—í¬í¬ë‹¹ í‰ê·  ì†ë„: {total_time/n_epochs:.2f}ì´ˆ/ì—í¬í¬")
        print(f"ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ì£¼ì¸ë‹˜, PyTorch MNIST GAN í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤!")
    
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
    config = {
        'batch_size': 100,
        'z_dim': 100,
        'lr': 0.0002,
        'n_epochs': 200,
        'save_interval': 50
    }
    
    print(f"ì„¤ì •: {config}")
    
    # CUDA ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•œ CPU ê°•ì œ ëª¨ë“œ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
    # force_cpu = torch.device('cpu')
    
    # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™” ë° í›ˆë ¨ ì‹œì‘
    trainer = MNISTGANTrainer(
        batch_size=config['batch_size'],
        z_dim=config['z_dim'],
        lr=config['lr']
        # device=force_cpu  # CUDA ë¬¸ì œ ì‹œ ì£¼ì„ í•´ì œ
    )
    
    trainer.train(
        n_epochs=config['n_epochs'],
        save_interval=config['save_interval']
    )
    
    print("ì£¼ì¸ë‹˜, í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")


if __name__ == "__main__":
    main()
